## SpecStory

## 모델 성능 개선 및 대체 모델 논의 (1/11/2025, 7:25:55 PM)

_**User**_

흠 @trainer copy 2.py 를 돌린 결과 성능이 만족스럽지 않은데, 어떻게 하면 성능을 올릴 수 있을까 혹시 너가 생각하기에 더 적합한 모델이 존재해? XGBoost를 대체할? @Web 을 참고해도 좋아. 아니면 XGBoost를 개선할 방법을 알려줘도 좋고.

네가 나의 질문에 초개인화된 응답을 할 수 있도록, 의도와 목적을 명확히 이해할 때까지 질문한 뒤 응답해 줘. 또한 기존 파일에 대한 질문을 받거나, 수정을 해야될 땐 절대 형식이나 내용을 임의로 가정하지 말고 실제 데이터를 참고해.

---

_**Assistant**_

먼저 현재 상황과 목표를 명확히 이해하고 싶습니다:

1. 현재 모델의 성능이 만족스럽지 않다고 하셨는데, 구체적으로 어떤 부분이 문제인가요?
   - 초기 모델: 정확도 0.811, ROC-AUC 0.996
   - 파인튜닝 후: 정확도 0.979, ROC-AUC 0.999
   
   수치상으로는 매우 좋아 보이는데, 실제 사용에서 어떤 문제가 있나요?

2. 데이터셋의 특성을 보면:
   - 총 634개의 샘플
   - 95개의 평가 데이터
   - 38개의 특성을 사용 중

3. 현재 앙상블 모델은:
   - XGBoost
   - CatBoost
   - Neural Network

이러한 상황에서 구체적으로 어떤 개선을 원하시나요?
- 예측 정확도 향상?
- 과적합 방지?
- 특정 상황에서의 성능 개선?
- 아니면 다른 목표가 있으신가요?

---

_**User**_

현재 모델의 성능이 만족스럽지 않다고 하셨는데, 구체적으로 어떤 부분이 문제인가요?
초기 모델: 정확도 0.811, ROC-AUC 0.996
파인튜닝 후: 정확도 0.979, ROC-AUC 0.999
수치상으로는 매우 좋아 보이는데, 실제 사용에서 어떤 문제가 있나요? -> 앙상블 후에는 괜찮아지지만 개별 모델의 성능이 좋지는 않아. 이러면 위험할 수 있어.

데이터셋의 특성을 보면:
총 634개의 샘플
95개의 평가 데이터
38개의 특성을 사용 중
현재 앙상블 모델은:
XGBoost
CatBoost
Neural Network
이러한 상황에서 구체적으로 어떤 개선을 원하시나요? 각 모델의 성능을 개선할 방법 혹은 특정 모델을 더 이 예측 상황에 맞는 모델로 개선할 수 있는 방법을 찾으면 좋겠어.

예측 정확도 향상? 응
과적합 방지? 응
특정 상황에서의 성능 개선? 성능은 올리되, 잘못예측하는 케이스 최대한 줄이기


---

_**Assistant**_

이해했습니다. 주요 문제점과 목표가 명확해졌네요:

1. 개별 모델의 성능이 낮음 (파인튜닝 결과에서):
   - XGBoost: CV 정확도 0.547
   - CatBoost: CV 정확도 0.667
   - Neural Network: CV 정확도 0.493

2. 목표:
   - 개별 모델의 성능 향상
   - 과적합 방지
   - 오예측 케이스 최소화

현재 코드를 분석해보면, 다음과 같은 개선사항을 제안할 수 있습니다:

1. LightGBM 추가 제안:
```python
model_param_grid = {
    'n_estimators': [200, 300],
    'learning_rate': [0.01, 0.005],
    'num_leaves': [31, 127],
    'max_depth': [4, 6],
    'min_data_in_leaf': [20, 30],
    'feature_fraction': [0.7, 0.9],
    'bagging_fraction': [0.7, 0.9],
    'bagging_freq': [5],
    'reg_alpha': [0.1, 0.5],
    'reg_lambda': [0.1, 0.5],
    'min_split_gain': [0.1],
    'min_child_weight': [1, 5]
}
```

2. XGBoost 파라미터 개선:
```python
model_param_grid = {
    'learning_rate': [0.01, 0.005],
    'n_estimators': [200, 300],
    'max_depth': [4, 6],
    'min_child_weight': [1, 3],
    'gamma': [0.1, 0.2],
    'subsample': [0.8, 0.9],
    'colsample_bytree': [0.8, 0.9],
    'reg_alpha': [0.1, 0.5],
    'reg_lambda': [0.1, 0.5],
    'scale_pos_weight': [1]
}
```

3. 특성 엔지니어링 개선:
```python
def prepare_features(self, data: List[Dict]) -> Tuple[pd.DataFrame, pd.Series]:
    # 기존 코드...
    
    # 추가할 특성들
    features.extend([
        # 팀간 상대적 지표
        'home_vs_away_win_rate_diff',
        'home_vs_away_recent_score_diff',
        'home_vs_away_field_goal_pct_diff',
        
        # 이동 평균 지표
        'home_rolling_win_rate_5',
        'away_rolling_win_rate_5',
        
        # 상호작용 특성
        'home_field_goal_pct_x_recent_win_rate',
        'away_field_goal_pct_x_recent_win_rate'
    ])
```

4. 교차 검증 전략 개선:
```python
def custom_cv_split(X, y, n_splits=5):
    # 시간 기반 분할 + 계층적 샘플링
    splits = []
    for train_idx, val_idx in TimeSeriesSplit(n_splits=n_splits).split(X):
        # 각 폴드에서 승/패 비율 유지
        train_idx = stratified_sample(train_idx, y[train_idx])
        splits.append((train_idx, val_idx))
    return splits
```

이러한 변경사항들을 구현하기 전에, 어떤 방향으로 먼저 시도해보고 싶으신가요? 각각의 개선사항에 대해 더 자세히 설명드릴 수 있습니다.

---

_**User**_

일단 모델 자체를 개선하는 방법을 먼저 시도하고 싶어. 다만 현재 grid도 시간을 꽤 잡아먹기 때문에 조합 케이스가 너무 많아지는 건 원하지 않아

---

_**Assistant**_

이해했습니다. 현재 grid 크기를 크게 늘리지 않으면서 각 모델의 성능을 개선할 수 있는 파라미터 조정을 제안하겠습니다.

```python:src/models/trainer copy 2.py
# 시간 가중치는 유지
weight_param_grid = {
    'weight_start': [0.4, 0.5],
    'weight_end': [0.8, 0.9],
}

# XGBoost 파라미터 개선
if model_type == 'xgboost':
    model_param_grid = {
        'learning_rate': [0.01, 0.03],
        'n_estimators': [200],  # 증가된 트리 수
        'max_depth': [4, 6],    # 트리 깊이 제어 추가
        'subsample': [0.8],     # 데이터 샘플링으로 과적합 방지
        'colsample_bytree': [0.8],  # 특성 샘플링
        'reg_lambda': [2.0],
        'reg_alpha': [0.1]
    }

# CatBoost 파라미터 개선
elif model_type == 'catboost':
    model_param_grid = {
        'iterations': [200],     # 증가된 반복 수
        'learning_rate': [0.01, 0.03],
        'depth': [4, 6],        # 트리 깊이 옵션 추가
        'l2_leaf_reg': [3],
        'subsample': [0.8],
        'random_strength': [1],
        'grow_policy': ['Depthwise']  # 트리 생성 정책 지정
    }

# Neural Network 파라미터 개선
else:
    model_param_grid = {
        'hidden_layer_sizes': [(64, 32), (128, 64)],  # 네트워크 구조 옵션 추가
        'learning_rate_init': [0.0001],  # 더 안정적인 학습률
        'max_iter': [500],
        'alpha': [0.0001],      # 약간 증가된 정규화
        'activation': ['relu'],
        'batch_size': [32],
        'early_stopping': [True],
        'n_iter_no_change': [10],  # 조기 종료 조건 완화
        'solver': ['adam'],
        'validation_fraction': [0.2]  # 검증 세트 비율 지정
    }
```

주요 변경사항 및 이유:

1. XGBoost:
   - max_depth 추가: 트리의 복잡도를 더 세밀하게 제어
   - subsample과 colsample_bytree 추가: 과적합 방지
   - n_estimators를 200으로 고정하고 다른 중요 파라미터에 집중

2. CatBoost:
   - depth 옵션 추가: 모델 복잡도 제어
   - grow_policy 지정: 더 안정적인 트리 생성
   - iterations를 200으로 고정하고 다른 파라미터에 집중

3. Neural Network:
   - 네트워크 구조 옵션 추가: 더 다양한 모델 탐색
   - 학습률 안정화: 0.0001로 조정
   - validation_fraction 추가: 더 안정적인 검증
   - n_iter_no_change 완화: 학습 기회 증가

이러한 변경은 grid 크기를 크게 늘리지 않으면서도:
- 과적합 방지
- 모델 안정성 향상
- 개별 모델의 성능 개선

에 초점을 맞췄습니다. 어떻게 생각하시나요?

---



---

