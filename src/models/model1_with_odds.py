# src/models/model1_with_odds.py
"""
ë°°ë‹¹ ë³€ìˆ˜ë¥¼ í¬í•¨í•œ LightGBM ëª¨ë¸
- ê¸°ì¡´ model1.py ë³µì‚¬ë³¸
- home_odds_bucket, away_odds_bucket ë³€ìˆ˜ ì¶”ê°€
- ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple
import json
import joblib
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.preprocessing import StandardScaler
from lightgbm import LGBMClassifier
from sklearn.model_selection import TimeSeriesSplit
from bayes_opt import BayesianOptimization


class BettingModel1WithOdds:
    """ë°°ë‹¹ ë³€ìˆ˜ë¥¼ í¬í•¨í•œ LightGBM ë² íŒ… ëª¨ë¸"""
    
    def __init__(self):
        self.model = None
        self.feature_names = None
        self.model_dir = Path(__file__).parent / "saved_models"
        self.model_dir.mkdir(exist_ok=True)
        self.dates = None  # ë‚ ì§œ ì •ë³´ ì €ì¥ì„ ìœ„í•œ ë³€ìˆ˜ ì¶”ê°€
    
    def prepare_features(self, data: List[Dict]) -> Tuple[pd.DataFrame, pd.Series]:
        """ë°ì´í„°ì—ì„œ íŠ¹ì„±ê³¼ ë ˆì´ë¸” ì¶”ì¶œ (ë°°ë‹¹ ë³€ìˆ˜ í¬í•¨!)"""
        df = pd.DataFrame(data)
        
        # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date')
        self.dates = df['date']  # ë‚ ì§œ ì •ë³´ ì €ì¥
        
        # ìŠ¹íŒ¨ ë ˆì´ë¸” ìƒì„± (í™ˆíŒ€ ê¸°ì¤€)
        y = (df['home_team_score'] > df['away_team_score']).astype(int)
        
        # ê¸°ë³¸ íŠ¹ì„± ì„ íƒ (ê¸°ì¡´ê³¼ ë™ì¼)
        base_features = [
            # ê¸°ë³¸ ê²½ê¸°ë ¥ ì§€í‘œ
            'home_rebounds', 'away_rebounds',
            'home_assists', 'away_assists',
            'home_fieldGoalsAttempted', 'away_fieldGoalsAttempted',
            'home_fieldGoalsMade', 'away_fieldGoalsMade',
            'home_fieldGoalPct', 'away_fieldGoalPct',
            'home_freeThrowsAttempted', 'away_freeThrowsAttempted',
            'home_freeThrowsMade', 'away_freeThrowsMade',
            'home_freeThrowPct', 'away_freeThrowPct',
            'home_threePointFieldGoalsAttempted', 'away_threePointFieldGoalsAttempted',
            'home_threePointFieldGoalsMade', 'away_threePointFieldGoalsMade',
            'home_threePointPct', 'away_threePointPct',
            
            # ë¦¬ë” í†µê³„
            'home_leader_points', 'away_leader_points',
            'home_leader_rebounds', 'away_leader_rebounds',
            'home_leader_assists', 'away_leader_assists',
            
            # íŒ€ ê¸°ë¡
            'home_overall_record_win_rate', 'away_overall_record_win_rate',
            'home_home_record_win_rate', 'away_home_record_win_rate',
            'home_road_record_win_rate', 'away_road_record_win_rate',
            'home_vs_away_win_rate',
            
            # ìµœê·¼ íŠ¸ë Œë“œ
            'home_recent_win_rate', 'away_recent_win_rate',
            'home_recent_avg_score', 'away_recent_avg_score',
            'home_recent_home_win_rate', 'away_recent_home_win_rate',
            'home_recent_away_win_rate', 'away_recent_away_win_rate',
            
            # ì»¨ë””ì…˜
            'home_rest_days', 'away_rest_days'
        ]
        
        # ê¸°ë³¸ íŠ¹ì„±ìœ¼ë¡œ DataFrame ìƒì„±
        X = df[base_features].copy()
        
        # ìµœê·¼ íŠ¸ë Œë“œ íŠ¹ì„± ë³µì œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        recent_features = [
            'recent_win_rate',
            'recent_avg_score',
            'recent_home_win_rate',
            'recent_away_win_rate'
        ]
        
        # ë³µì œëœ íŠ¹ì„± ì¶”ê°€
        for col in recent_features:
            for team in ['home', 'away']:
                orig_col = f'{team}_{col}'
                new_col = f'{orig_col}_2'
                X[new_col] = X[orig_col]  # ë™ì¼í•œ ê°’ìœ¼ë¡œ ë³µì œ
        
        # â˜…â˜…â˜… ë°°ë‹¹ ë³€ìˆ˜ ì¶”ê°€ (ìƒˆë¡œ ì¶”ê°€!) â˜…â˜…â˜…
        if 'home_odds_bucket' in df.columns and 'away_odds_bucket' in df.columns:
            X['home_odds_bucket'] = df['home_odds_bucket']
            X['away_odds_bucket'] = df['away_odds_bucket']
            print(f"\nâœ… ë°°ë‹¹ ë³€ìˆ˜ ì¶”ê°€ë¨: home_odds_bucket, away_odds_bucket")
        else:
            print(f"\nâš ï¸ ë°°ë‹¹ ë³€ìˆ˜(home_odds_bucket, away_odds_bucket)ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤!")
        
        self.feature_names = X.columns.tolist()
        
        return X, y
    

    def train_model(self, X: pd.DataFrame, y: pd.Series) -> Dict:
        """ìµœì  íŒŒë¼ë¯¸í„°ë¡œ LightGBM ëª¨ë¸ í•™ìŠµ (ê¸°ì¡´ê³¼ ë™ì¼í•œ íŒŒë¼ë¯¸í„°!)"""
        from lightgbm import LGBMClassifier
        import numpy as np

        n_samples = len(X)
        # ì§€ìˆ˜ì  ì¦ê°€ ê°€ì¤‘ì¹˜ (ìµœê·¼ ë°ì´í„°ì— ë” ê¸‰ê²©í•œ ê°€ì¤‘ì¹˜)
        sample_weights = np.exp(np.linspace(0, 1, n_samples))

        # ê¸°ì¡´ê³¼ ë™ì¼í•œ íŒŒë¼ë¯¸í„° ì‚¬ìš©!
        best_params = {
            'colsample_bytree': 0.7,        # ë” ë§ì€ íŠ¹ì„± ì‚¬ìš©
            'learning_rate': 0.05,          # ë‚®ì€ í•™ìŠµë¥ ë¡œ ì•ˆì •ì  í•™ìŠµ
            'max_depth': 4,                 # ì ë‹¹í•œ ê¹Šì´ë¡œ ê³¼ì í•© ë°©ì§€
            'min_child_samples': 70,        # ì•ˆì •ì ì¸ ë¦¬í”„ ë…¸ë“œ
            'n_estimators': 300,            # ì¶©ë¶„í•œ íŠ¸ë¦¬ ê°œìˆ˜
            'num_leaves': 24,               # ì ì€ ë¦¬í”„ ë…¸ë“œë¡œ ê³¼ì í•© ë°©ì§€
            'reg_alpha': 1.0,               # L1 ê·œì œ
            'reg_lambda': 10.0,             # L2 ê·œì œ
            'subsample': 0.65,               # ë°ì´í„° ìƒ˜í”Œë§ìœ¼ë¡œ ê³¼ì í•© ë°©ì§€
            'random_state': 42,
            'verbose': -1,
            'boosting_type': 'gbdt',
            'importance_type': 'gain',
            'feature_fraction_seed': 42,
            'bagging_seed': 42
        }
        
        # ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ
        self.model = LGBMClassifier(**best_params)
        
        print("\n=== ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ë°°ë‹¹ ë³€ìˆ˜ í¬í•¨) ===")
        print(f"ì´ íŠ¹ì„± ìˆ˜: {len(self.feature_names)}")
        print(f"ìƒ˜í”Œ ìˆ˜: {len(X)}")
        
        self.model.fit(X, y, sample_weight=sample_weights)
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚° (gain ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½í•˜ê³  ì •ê·œí™”)
        importances = self.model.booster_.feature_importance(importance_type='gain')
        importances = 100.0 * (importances / importances.sum())  # í¼ì„¼íŠ¸ë¡œ ë³€í™˜
        
        metrics = {
            'feature_importance': dict(zip(
                self.feature_names,
                importances
            ))
        }
        
        # ìƒìœ„ 15ê°œ ì¤‘ìš” íŠ¹ì„± ì¶œë ¥ (ë°°ë‹¹ ë³€ìˆ˜ í™•ì¸ìš©)
        print("\n=== ìƒìœ„ 15ê°œ ì¤‘ìš” íŠ¹ì„± (%) ===")
        sorted_features = sorted(
            metrics['feature_importance'].items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:15]
        for feature, importance in sorted_features:
            marker = "â­" if 'odds' in feature else ""
            print(f"{marker}{feature}: {importance:.2f}%")
        
        # ë°°ë‹¹ ë³€ìˆ˜ ì¤‘ìš”ë„ ë³„ë„ ì¶œë ¥
        print("\n=== ë°°ë‹¹ ë³€ìˆ˜ ì¤‘ìš”ë„ ===")
        for feature in ['home_odds_bucket', 'away_odds_bucket']:
            if feature in metrics['feature_importance']:
                importance = metrics['feature_importance'][feature]
                print(f"  {feature}: {importance:.2f}%")
        
        return metrics
    
    def evaluate_recent_games(self, X: pd.DataFrame, y: pd.Series, n_games: int = 50) -> Dict:
        """í•™ìŠµëœ ëª¨ë¸ë¡œ ìµœê·¼ Nê²½ê¸° ì˜ˆì¸¡ ì„±ëŠ¥ í‰ê°€"""
        from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix
        
        # ìµœê·¼ n_games ì„ íƒ
        X_recent = X[-n_games:]
        y_recent = y[-n_games:]
        dates_recent = self.dates[-n_games:]
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        y_pred = self.model.predict(X_recent)
        y_pred_proba = self.model.predict_proba(X_recent)[:, 1]
        
        # í˜¼ë™ í–‰ë ¬ ê³„ì‚°
        conf_matrix = confusion_matrix(y_recent, y_pred)
        
        # ê²°ê³¼ ì €ì¥
        results = {
            'accuracy': accuracy_score(y_recent, y_pred),
            'roc_auc': roc_auc_score(y_recent, y_pred_proba),
            'confusion_matrix': conf_matrix.tolist(),
            'predictions': list(zip(
                dates_recent.dt.strftime('%Y-%m-%d').tolist(),
                y_recent.tolist(),
                y_pred.tolist(),
                y_pred_proba.tolist()
            ))
        }
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\n=== ìµœê·¼ {n_games}ê²½ê¸° ì˜ˆì¸¡ ì„±ëŠ¥ ===")  # ë™ì  ë©”ì‹œì§€ë¡œ ìˆ˜ì •
        print(f"ì •í™•ë„: {results['accuracy']:.3f}")
        print(f"ROC-AUC: {results['roc_auc']:.3f}")
        print("\ní˜¼ë™ í–‰ë ¬:")
        print(f"TN: {conf_matrix[0,0]}, FP: {conf_matrix[0,1]}")
        print(f"FN: {conf_matrix[1,0]}, TP: {conf_matrix[1,1]}")
        
        print("\n=== ìµœê·¼ 10ê²½ê¸° ì˜ˆì¸¡ ìƒì„¸ ===")
        for date, true, pred, prob in results['predictions'][-10:]:
            print(f"ë‚ ì§œ: {date}, ì‹¤ì œ: {true}, ì˜ˆì¸¡: {pred}, ìŠ¹ë¦¬í™•ë¥ : {prob:.3f}")
        
        return results
    
    def save_model(self, timestamp: str = None) -> None:
        """í•™ìŠµëœ ëª¨ë¸ê³¼ íŠ¹ì„± ì´ë¦„ì„ ì €ì¥"""
        if self.model is None:
            raise ValueError("ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.")
        
        if timestamp is None:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (with_odds ì ‘ë¯¸ì‚¬ ì¶”ê°€)
        model_path = self.model_dir / f"betting_model1_with_odds_{timestamp}.joblib"
        feature_path = self.model_dir / f"features1_with_odds_{timestamp}.json"
        
        # ëª¨ë¸ ì €ì¥
        joblib.dump(self.model, model_path)
        
        # íŠ¹ì„± ì´ë¦„ ì €ì¥
        with open(feature_path, 'w') as f:
            json.dump({
                'feature_names': self.feature_names,
                'model_info': {
                    'type': 'lightgbm_with_odds',
                    'params': self.model.get_params(),
                    'odds_buckets': 8  # 8êµ¬ê°„ ì‚¬ìš©
                }
            }, f, indent=2)
        
        print(f"\n=== ëª¨ë¸ ì €ì¥ ì™„ë£Œ ===")
        print(f"ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model_path}")
        print(f"íŠ¹ì„± ì •ë³´ ì €ì¥ ê²½ë¡œ: {feature_path}")


def get_latest_processed_data_with_odds() -> List[Dict]:
    """src/data í´ë”ì—ì„œ ê°€ì¥ ìµœì‹ ì˜ processed_with_odds json íŒŒì¼ ë¡œë“œ"""
    data_dir = Path(__file__).parent.parent / "data"
    
    # processed_with_odds íŒŒì¼ ì°¾ê¸°
    json_files = list(data_dir.glob("processed_with_odds_*.json"))
    
    if not json_files:
        raise FileNotFoundError("ë°°ë‹¹ í¬í•¨ ì²˜ë¦¬ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                               "ë¨¼ì € processor_model_with_odds.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
    print(f"ë°ì´í„° íŒŒì¼ ë¡œë“œ: {latest_file.name}")
    
    with open(latest_file, 'r') as f:
        return json.load(f)


if __name__ == "__main__":
    print("=" * 70)
    print("ğŸ€ ë°°ë‹¹ ë³€ìˆ˜ í¬í•¨ LightGBM ëª¨ë¸ í•™ìŠµ")
    print("=" * 70)
    
    # ìµœì‹  ë°°ë‹¹ í¬í•¨ ë°ì´í„° ë¡œë“œ
    data = get_latest_processed_data_with_odds()
    
    # ëª¨ë¸ ì´ˆê¸°í™” ë° íŠ¹ì„± ì¤€ë¹„
    model = BettingModel1WithOdds()
    X, y = model.prepare_features(data)
    
    print("\n=== ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ ===")
    print(f"íŠ¹ì„± ìˆ˜: {len(model.feature_names)}")
    print(f"ìƒ˜í”Œ ìˆ˜: {len(X)}")
    print(f"ë°°ë‹¹ ë³€ìˆ˜ í¬í•¨ ì—¬ë¶€: {'home_odds_bucket' in model.feature_names}")
    
    # ì „ì²´ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ
    metrics = model.train_model(X, y)
    
    # ìµœê·¼ 70ê²½ê¸° ì„±ëŠ¥ í‰ê°€
    eval_results = model.evaluate_recent_games(X, y, n_games=70)
    
    # ëª¨ë¸ ì €ì¥
    model.save_model()
    
    print("\n" + "=" * 70)
    print("âœ… ë°°ë‹¹ ë³€ìˆ˜ í¬í•¨ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    print("=" * 70)

